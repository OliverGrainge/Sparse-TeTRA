
pretrain:
  module:
    model_name: ViT
    model_init_args: 
      image_size: 224
      patch_size: 16
      dim: 768  # Increased model dimension
      depth: 12  # Increased number of layers
      heads: 12  # Increased number of attention heads 
      mlp_dim: 3072  # Increased MLP dimension
      in_channels: 3
      dim_head: 64
      dropout: 0.1
      emb_dropout: 0.1
      embedding_norm: "LayerNorm"
      embedding_linear: "Linear"
      attention_linear_layer: "SparseTernaryLinear"
      attention_norm_layer: "LayerNorm"
      feedforward_linear_layer: "SparseTernaryLinear"
      feedforward_norm_layer: "LayerNorm"
      feedforward_activation_layer: "GELU"
    
    lr: 0.0003
    weight_decay: 0.001

  data: 
    train_data_dir: "/home/oliver/datasets_drive/vpr_datasets/gsv-cities/Images"
    batch_size: 64
    num_workers: 14
    img_size: 224
    pin_memory: true

  trainer:
    max_epochs: 50  # Reduced number of epochs
    accelerator: "auto"
    devices: "auto"
    precision: 16
