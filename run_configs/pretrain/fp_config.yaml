
model:
  model_name: ViT
  model_init_args: 
    image_size: 224
    patch_size: 16
    dim: 384  # Reduced model dimension
    depth: 4   # Reduced number of layers
    heads: 6   # Reduced number of attention heads
    mlp_dim: 1536  # Reduced MLP dimension
    in_channels: 3
    dim_head: 64
    dropout: 0.1  # Added some dropout for regularization
    emb_dropout: 0.1
    embedding_norm: "LayerNorm"
    embedding_linear: "Linear"
    attention_linear_layer: "Linear"
    attention_norm_layer: "LayerNorm"
    feedforward_linear_layer: "Linear"
    feedforward_norm_layer: "LayerNorm"
    feedforward_activation_layer: "GELU"
  
  lr: 0.0003
  weight_decay: 0.001

  data: 
    train_data_dir: "/home/oliver/datasets_drive/vpr_datasets/sf_xl/small/train"
    batch_size: 128
    num_workers: 8
    img_size: 224
    pin_memory: true

  trainer:
    max_epochs: 1  # Reduced number of epochs
    accelerator: "auto"
    devices: "auto"
    precision: 16