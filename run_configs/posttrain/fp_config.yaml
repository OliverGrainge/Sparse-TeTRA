
posttrain: 
  module: 
    model_name: ViT
    checkpoint_path: "checkpoints/pretrain/ViT/fp_config_epoch=0-train_loss=3.4735.ckpt"

    model_init_args:
      image_size: 224
      patch_size: 16
      dim: 384  # Reduced model dimension
      depth: 6   # Reduced number of layers
      heads: 6   # Reduced number of attention heads
      mlp_dim: 1536  # Reduced MLP dimension
      in_channels: 3
      dim_head: 64
      dropout: 0.1  # Added some dropout for regularization
      emb_dropout: 0.1
      embedding_norm: "LayerNorm"
      embedding_linear: "Linear"
      attention_linear_layer: "Linear"
      attention_norm_layer: "LayerNorm"
      feedforward_linear_layer: "Linear"
      feedforward_norm_layer: "LayerNorm"
      feedforward_activation_layer: "GELU"
    
    agg_name: cls
    agg_init_args: {}


  data: 
    train_data_dir: "/home/oliver/datasets_drive/vpr_datasets/gsv-cities/" 
    val_data_dir: "/home/oliver/datasets_drive/vpr_datasets"
    batch_size: 64
    img_per_place: 4
    min_img_per_place: 4
    shuffle_all: False
    image_size:
      - 224
      - 224
    num_workers: 0
    val_set_names:
      - msls
      - eynsham

  trainer:
    max_epochs: 1 
    accelerator: "auto"
    devices: "auto"
    precision: 32
    num_sanity_val_steps: 0
    limit_train_batches: 5
